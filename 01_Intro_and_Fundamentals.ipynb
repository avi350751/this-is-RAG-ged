{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2c3f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb012e",
   "metadata": {},
   "source": [
    "### Creating a document manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fba760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      "I want to learn Langchain\n",
      "\n",
      "Metadata: \n",
      "{'source': 'introduction.txt', 'author': 'langchain team', 'date': '2025-01-15'}\n"
     ]
    }
   ],
   "source": [
    "from importlib import metadata\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"I want to learn Langchain\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction.txt\",\n",
    "        \"author\": \"langchain team\",\n",
    "        \"date\": \"2025-01-15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Access the content\n",
    "print(\"Content: \" )\n",
    "print(doc.page_content)\n",
    "print(\"\\nMetadata: \")\n",
    "print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da2b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Document 1:\n",
      " Content: I want to learn Langchain\n",
      " Author: langchain team\n",
      "\n",
      " Document 2:\n",
      " Content: I want to learn Langgraph\n",
      " Author: langgraph team\n",
      "\n",
      " Document 3:\n",
      " Content: I want to learn Langflow\n",
      " Author: Agentic AI team\n"
     ]
    }
   ],
   "source": [
    "# Create a multiple documents\n",
    "documents = [\n",
    "    Document(\n",
    "    page_content=\"I want to learn Langchain\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction.txt\",\n",
    "        \"author\": \"langchain team\",\n",
    "        \"date\": \"2025-01-15\"\n",
    "    }\n",
    "),\n",
    "    Document(\n",
    "        page_content=\"I want to learn Langgraph\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction_01.txt\",\n",
    "        \"author\": \"langgraph team\",\n",
    "        \"date\": \"2026-01-02\"\n",
    "    }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"I want to learn Langflow\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction_02.txt\",\n",
    "        \"author\": \"Agentic AI team\",\n",
    "        \"date\": \"2026-01-01\"\n",
    "    }\n",
    "    )\n",
    "]\n",
    "\n",
    "# Print all documents\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"\\n Document {i}:\")\n",
    "    print(f\" Content: {doc.page_content}\")\n",
    "    print(f\" Author: {doc.metadata[\"author\"]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd20eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello LANGCHAIN !!'\n",
      "Step1: add_prefix -> Hi hello LANGCHAIN !!\n",
      "Step2: uppercase -> HI HELLO LANGCHAIN !!\n",
      "Step3: lowercase -> hi hello langchain !!\n",
      "Final Output is: hi hello langchain !!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def add_prefix(text: str) -> str:\n",
    "    result = f\"Hi {text}\"\n",
    "    print(f\"Step1: add_prefix -> {result}\")\n",
    "    return result\n",
    "\n",
    "def uppercase(text: str) -> str:\n",
    "    print(f\"Step2: uppercase -> {text.upper()}\")\n",
    "    return text.upper()\n",
    "\n",
    "def lowercase(text: str) -> str:\n",
    "    print(f\"Step3: lowercase -> {text.lower()}\")\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Create runnables\n",
    "uppercase_runnable = RunnableLambda(uppercase)\n",
    "lowercase_runnable = RunnableLambda(lowercase)\n",
    "prefix_runnable = RunnableLambda(add_prefix)\n",
    "\n",
    "# Build the chain\n",
    "chain =  prefix_runnable | uppercase_runnable | lowercase_runnable\n",
    "\n",
    "# Execute the chain\n",
    "print(\"Input: 'hello LANGCHAIN !!'\")\n",
    "response = chain.invoke(\"hello LANGCHAIN !!\")\n",
    "print(f\"Final Output is: {response}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5866733",
   "metadata": {},
   "source": [
    "## First LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b11874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : Who wrote 'Man-Eaters of Kumaon?\n",
      "\n",
      "Answer: **'Man-Eaters of Kumaon'** was written by **Jim Corbett**.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature =0\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Who wrote 'Man-Eaters of Kumaon?\")\n",
    "\n",
    "print(\"Question : Who wrote 'Man-Eaters of Kumaon?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057df8b6",
   "metadata": {},
   "source": [
    "## Understanding the response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a809269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: **'Man-Eaters of Kumaon'** was written by **Jim Corbett**.\n",
      "\n",
      "Response Metadata: \n",
      "{'token_usage': {'completion_tokens': 19, 'prompt_tokens': 17, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_1a2c4a5ede', 'id': 'chatcmpl-Cty2njFZTqvEyYe41Wo5zKno92D38', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n",
      "\n",
      "Tokens Used: \n",
      " Completion Tokens: 19\n",
      " Total Tokens: 36\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Type:\", type(response))\n",
    "print(\"\\nContent:\", response.content)\n",
    "print(\"\\nResponse Metadata: \")\n",
    "print(response.response_metadata)\n",
    "\n",
    "if 'token_usage' in response.response_metadata:\n",
    "    usage = response.response_metadata['token_usage']\n",
    "    print(f\"\\nTokens Used: \")\n",
    "    print(f\" Completion Tokens: {usage.get('completion_tokens')}\")\n",
    "    print(f\" Total Tokens: {usage.get('total_tokens')}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd029fb",
   "metadata": {},
   "source": [
    "## Using Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f57e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Template:\n",
      "Explain {topic} in  simple terms suitable for beginners\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain {topic} in  simple terms suitable for beginners\"\n",
    ")\n",
    "\n",
    "print(\"Prompt Template:\")\n",
    "print(prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a5aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Topic: MACHINE LEARNING\n",
      "============================================================\n",
      "Sure! Here’s a simple explanation of **machine learning**:\n",
      "\n",
      "---\n",
      "\n",
      "**Machine learning** is a way for computers to learn from experience, kind of like how humans do.\n",
      "\n",
      "- Imagine you want to teach a computer to tell the difference between cats and dogs in pictures.\n",
      "- Instead of telling the computer all the rules (like \"cats have pointy ears\"), you show it lots of pictures of cats and dogs, and tell it which is which.\n",
      "- The computer looks for patterns in the pictures to figure out what makes a cat a cat, and a dog a dog.\n",
      "- After seeing enough examples, the computer can start guessing if a new picture is a cat or a dog—even if it’s never seen that exact picture before.\n",
      "\n",
      "**In short:**  \n",
      "Machine learning is when computers learn from data and examples, so they can make decisions or predictions without being told exactly what to do.\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you want more details or examples!\n",
      "\n",
      "============================================================\n",
      "Topic: ARTIFICIAL INTELLIGENCE\n",
      "============================================================\n",
      "Sure! Here’s a simple explanation of **artificial intelligence (AI)**:\n",
      "\n",
      "**Artificial intelligence** is when computers or machines are made to think and act like humans. This means they can learn from experience, understand things, solve problems, and make decisions—just like people do.\n",
      "\n",
      "For example, when you talk to a voice assistant like Siri or Alexa, it understands your words and tries to help you. That’s AI at work! Or when you see recommendations for movies on Netflix, AI is helping to choose what you might like.\n",
      "\n",
      "In short, AI is about making computers smart so they can help us in different ways.\n",
      "\n",
      "============================================================\n",
      "Topic: AGENTIC AI\n",
      "============================================================\n",
      "Sure! Here’s a simple explanation of **Agentic AI**:\n",
      "\n",
      "---\n",
      "\n",
      "**Agentic AI** means an artificial intelligence (AI) system that can act on its own to achieve goals.\n",
      "\n",
      "- **Agentic** comes from the word “agent,” which means someone or something that does things.\n",
      "- So, **Agentic AI** is an AI that doesn’t just follow instructions step by step, but can make decisions, plan actions, and try to reach a goal by itself.\n",
      "\n",
      "**Example:**\n",
      "- A regular AI might just answer your questions.\n",
      "- An agentic AI could help you plan a trip: it would search for flights, book hotels, and remind you to pack, all by itself, based on your goal (“I want to go to Paris next month”).\n",
      "\n",
      "**In short:**  \n",
      "Agentic AI is like a helpful assistant that can figure out what to do and take actions for you, not just answer questions or follow simple commands.\n",
      "\n",
      "============================================================\n",
      "Topic: QUANTUM COMPUTING\n",
      "============================================================\n",
      "Absolutely! Here’s a simple explanation of **quantum computing**:\n",
      "\n",
      "---\n",
      "\n",
      "### What is Quantum Computing?\n",
      "\n",
      "**Quantum computing** is a new way of making computers that uses the strange rules of quantum physics.\n",
      "\n",
      "---\n",
      "\n",
      "### How is it different from regular computers?\n",
      "\n",
      "- **Regular computers** use **bits**. Each bit is either a 0 or a 1.\n",
      "- **Quantum computers** use **qubits** (quantum bits). A qubit can be a 0, a 1, or **both at the same time** (this is called **superposition**).\n",
      "\n",
      "---\n",
      "\n",
      "### Why is this special?\n",
      "\n",
      "Because qubits can be in many states at once, quantum computers can process lots of possibilities at the same time. This could make them much faster for certain problems.\n",
      "\n",
      "---\n",
      "\n",
      "### Another cool thing: Entanglement\n",
      "\n",
      "Qubits can also be **entangled**. This means the state of one qubit can depend on another, even if they’re far apart. This helps quantum computers solve problems in ways regular computers can’t.\n",
      "\n",
      "---\n",
      "\n",
      "### What can quantum computers do?\n",
      "\n",
      "They could help with:\n",
      "- Breaking codes (cryptography)\n",
      "- Discovering new medicines\n",
      "- Solving really hard math problems\n",
      "- Simulating molecules and materials\n",
      "\n",
      "---\n",
      "\n",
      "### In short:\n",
      "\n",
      "**Quantum computers use the weirdness of quantum physics to solve some problems much faster than regular computers.**\n",
      "\n",
      "---\n",
      "\n",
      "If you want an analogy:  \n",
      "- **Regular computers** are like reading one page of a book at a time.\n",
      "- **Quantum computers** are like reading many pages at once!\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you want more details or examples!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "topics = [\"machine learning\", \"artificial intelligence\",\"Agentic AI\",\"Quantum computing\"]\n",
    "\n",
    "for topic in topics:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Topic: {topic.upper()}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    response = chain.invoke({\"topic\": topic})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9dd9c6",
   "metadata": {},
   "source": [
    "## Intermediate : Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27eef3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RAG:\n",
      " Absolutely! Here’s a simple explanation of **RAG**:\n",
      "\n",
      "---\n",
      "\n",
      "### What is RAG?\n",
      "\n",
      "**RAG** stands for **Ret....\n",
      "\n",
      "2. LCEL:\n",
      " Sure! Here’s a simple explanation of **LCEL**:\n",
      "\n",
      "---\n",
      "\n",
      "**LCEL** stands for **Life Cycle Environmental ....\n",
      "\n",
      "3. MAN-EATERS OF KUMAON:\n",
      " **Man-Eaters of Kumaon** is a famous book written by **Jim Corbett**. Here’s a simple explanation:\n",
      "\n",
      "....\n"
     ]
    }
   ],
   "source": [
    "# Process multiple inputs efficiently using .batch()\n",
    "\n",
    "topics_batch = [\n",
    "    {\"topic\": \"RAG\"},\n",
    "    {\"topic\": \"LCEL\"},\n",
    "    {\"topic\": \"Man-Eaters of Kumaon\"}\n",
    "]\n",
    "\n",
    "results = chain.batch(topics_batch)\n",
    "\n",
    "for i , (input_dict, result) in enumerate(zip(topics_batch, results),1):\n",
    "    print(f\"\\n{i}. {input_dict['topic'].upper()}:\")\n",
    "    print(f\" {result[:100]}....\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b83d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
